{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 2 (recommendation links) - Ongoing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NEXT: \n",
    "- 1 hyperlinks\n",
    "- create a functions to calcualte precentage of change by area \n",
    "- 2 send by emaiL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from selenium import webdriver \n",
    "import time\n",
    "import seaborn as sns \n",
    "from Hemnet import preprocessing,hemnet_generator, dep_filter,pct_change_metric\n",
    "from Scraper import url_extractor , scraper2\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from itertools import chain \n",
    "import numpy as np \n",
    "import re  \n",
    "from flask import Flask, request,render_template\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#zones = [18027,18028,18042,17951]\n",
    "#for area_code in zones:\n",
    "    #pct_change_metric (area_code , num_pages= 50, metric = 'pris_per_m2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'soup' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-75adfca25020>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mlinks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mlink\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msoup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindAll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'a'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'href'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"^https://www.hemnet\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mlinks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlink\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'href'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'soup' is not defined"
     ]
    }
   ],
   "source": [
    "#links = []\n",
    "#for link in soup.findAll('a', attrs={'href': re.compile(\"^https://www.hemnet\")}):\n",
    "    #links.append(link.get('href') )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "links"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Flask app "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NEXT: \n",
    "\n",
    "- Continue with docker\n",
    "- learn more css and html\n",
    "- choose the same structure and improve the design\n",
    "- choose how to distribute the funtions \n",
    "- how to display tables\n",
    "- Add info to the pipeline\n",
    "- https://github.com/kishan0725/AJAX-Movie-Recommendation-System-with-Sentiment-Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Pickle file using serialization - This step is on the notebook  \n",
    "\n",
    "pickle_out1 = open(\"scraper2.pkl\",\"wb\") # this file should be on my folder \n",
    "pickle.dump(scraper2, pickle_out1) # classifier is the name of the model \n",
    "\n",
    "pickle_out2 = open(\"url_extractor.pkl\",\"wb\") \n",
    "pickle.dump(url_extractor, pickle_out2) \n",
    "\n",
    "pickle_out3 = open(\"pct_change_metric.pkl\",\"wb\") \n",
    "pickle.dump(pct_change_metric, pickle_out3) \n",
    "\n",
    "pickle_out1.close()\n",
    "pickle_out2.close()\n",
    "pickle_out3.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
      "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n",
      "127.0.0.1 - - [18/Nov/2020 19:58:48] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INITIAL EXTRACTION...\n",
      "DONE WITH INITIAL EXTRACTION\n",
      "STEP 1: SCRAPING...\n",
      "STEP 2: GENERATING NEW FEATURES...\n",
      "STEP 3: OBTAINING HISTORICAL DATA TO CALCULATE PREDICTED PRICE...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [18/Nov/2020 20:00:12] \"\u001b[37mGET /predict?area=sundbyberg&keys=&min_year=1980&relevant_only=yes&sold_age=3m&loan_limit=3000000 HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP 4: GENERATING LAST FEATURES...\n",
      "DONE\n"
     ]
    }
   ],
   "source": [
    "# 1 create the flask env\n",
    "app = Flask(__name__)\n",
    "#Swagger(app)\n",
    "\n",
    "# 2 Open the file \n",
    "pickle_in1 = open(\"scraper2.pkl\",\"rb\")\n",
    "scraper2 = pickle.load(pickle_in1)\n",
    "\n",
    "pickle_in2 = open(\"url_extractor.pkl\",\"rb\")\n",
    "url_extractor = pickle.load(pickle_in2)\n",
    "\n",
    "pickle_in3 = open(\"pct_change_metric.pkl\",\"rb\")\n",
    "pct_change_metric = pickle.load(pickle_in3)\n",
    "\n",
    "@app.route('/')\n",
    "def welcome():\n",
    "    return render_template('index.html')\n",
    "\n",
    "@app.route('/predict',methods=[\"GET\"])\n",
    "def predict():\n",
    "    \n",
    "    # Remember to add new parameters here: \n",
    "    area = request.args.get(\"area\")\n",
    "    keys = request.args.get(\"keys\")\n",
    "    min_year = request.args.get(\"min_year\")\n",
    "    current_url = request.args.get(\"current_url\")\n",
    "    relevant_only = request.args.get(\"relevant_only\")\n",
    "    sold_age = request.args.get(\"sold_age\")\n",
    "    loan_limit = request.args.get(\"loan_limit\")\n",
    "\n",
    "    current_url_new = url_extractor(area, keys, min_year )\n",
    "\n",
    "    df = scraper2(current_url = current_url_new ,relevant_only = relevant_only ,sold_age = sold_age,loan_limit = int(loan_limit))\n",
    "\n",
    "    \n",
    "    return render_template('view.html',tables=[df.to_html(classes ='scraper')],\n",
    "    titles = ['na', 'Results'])\n",
    "\n",
    "@app.route('/comparison',methods=[\"GET\"])\n",
    "def compare_pct():\n",
    " \n",
    "    # Remember to add new parameters here: \n",
    "     \n",
    "    area = request.args.get(\"area\")\n",
    "    num_pages = request.args.get(\"num_pages\")\n",
    "    metric = request.args.get(\"metric\")\n",
    "\n",
    "    output = pct_change_metric(area = area, num_pages = num_pages , metric = metric )\n",
    "\n",
    "    return output\n",
    "\n",
    "if __name__=='__main__':\n",
    "    app.run()\n",
    "    \n",
    "\n",
    "# if __name__=='__main__':\n",
    "#     app.run(host='0.0.0.0',port=8000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Docker\n",
    "https://www.youtube.com/watch?v=cDwsaQoP4Lk&list=PLZoTAELRMXVNKtpy0U_Mx9N26w8n0hIbs&index=6 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GitHub pull request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/Tabe/Desktop/Courses/Data-Science /Test-Projects/Python-Projects/HemnetScraper\r\n"
     ]
    }
   ],
   "source": [
    "! pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already up to date.\n",
      "[master f919a36] Last run on 2020-11-13 13:15:46.943381\n",
      " 3 files changed, 65 insertions(+), 37 deletions(-)\n",
      "Enumerating objects: 11, done.\n",
      "Counting objects: 100% (11/11), done.\n",
      "Delta compression using up to 4 threads\n",
      "Compressing objects: 100% (5/5), done.\n",
      "Writing objects: 100% (6/6), 1.05 KiB | 1.05 MiB/s, done.\n",
      "Total 6 (delta 4), reused 0 (delta 0)\n",
      "remote: Resolving deltas: 100% (4/4), completed with 4 local objects.\u001b[K\n",
      "To https://github.com/tabers77/Python-Projects.git\n",
      "   44d8748..f919a36  master -> master\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "\n",
    "# 2 Pull request\n",
    "! git pull\n",
    "\n",
    "# 3\n",
    "now = datetime.datetime.now()\n",
    "commit_message = \"Last run on \" + str(now)\n",
    "! cd '/Users/Tabe/Desktop/Courses/Data-Science /Test-Projects/Python-Projects/HemnetScraper'\n",
    "! echo $commit_message > commit_message.txt\n",
    "! git add . \n",
    "! git commit -F commit_message.txt\n",
    "! git push origin master # here I choose either master or branch \n",
    "print ('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hemnet_env",
   "language": "python",
   "name": "hemnet_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
