{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 2 (recommendation links) - Ongoing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NEXT: \n",
    "- Choose the correct option for timers\n",
    "- remove timers\n",
    "- 1 hyperlinks\n",
    "- improve preprocessing \n",
    "- run in the brackground\n",
    "- 2 send by emaiL \n",
    "- https://stackoverflow.com/questions/46920243/how-to-configure-chromedriver-to-initiate-chrome-browser-in-headless-mode-throug "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from selenium import webdriver \n",
    "import time\n",
    "import seaborn as sns \n",
    "from Hemnet import preprocessing,hemnet_generator, dep_filter,pct_change_metric\n",
    "from Scraper import url_extractor , scraper2\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from itertools import chain \n",
    "import numpy as np \n",
    "import re  \n",
    "from flask import Flask, request,render_template\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#zones = [18027,18028,18042,17951]\n",
    "#for area_code in zones:\n",
    "    #pct_change_metric (area_code , num_pages= 50, metric = 'pris_per_m2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#links = []\n",
    "#for link in soup.findAll('a', attrs={'href': re.compile(\"^https://www.hemnet\")}):\n",
    "    #links.append(link.get('href') )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Flask app "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NEXT: \n",
    "\n",
    "- Continue with docker\n",
    "- learn more css and html\n",
    "- choose the same structure and improve the design\n",
    "- choose how to distribute the funtions \n",
    "- how to display tables\n",
    "- Add info to the pipeline\n",
    "- https://github.com/kishan0725/AJAX-Movie-Recommendation-System-with-Sentiment-Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Pickle file using serialization - This step is on the notebook  \n",
    "\n",
    "pickle_out1 = open(\"scraper2.pkl\",\"wb\") # this file should be on my folder \n",
    "pickle.dump(scraper2, pickle_out1) # classifier is the name of the model \n",
    "\n",
    "pickle_out2 = open(\"url_extractor.pkl\",\"wb\") \n",
    "pickle.dump(url_extractor, pickle_out2) \n",
    "\n",
    "pickle_out3 = open(\"pct_change_metric.pkl\",\"wb\") \n",
    "pickle.dump(pct_change_metric, pickle_out3) \n",
    "\n",
    "pickle_out1.close()\n",
    "pickle_out2.close()\n",
    "pickle_out3.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
      "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n",
      "127.0.0.1 - - [28/Nov/2020 08:25:18] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INITIAL EXTRACTION...\n",
      "DONE WITH INITIAL EXTRACTION\n",
      "STEP 1: SCRAPING - BASELINE...\n",
      "STEP 2: GENERATING NEW FEATURES...\n",
      "STEP 3: OBTAINING HISTORICAL DATA TO CALCULATE PREDICTED PRICE...\n",
      "STEP 4: GENERATING LAST FEATURES...\n",
      "STEP 2.1: CALCULATING DISTANCES\n",
      "CALCULATING FOR Margreteborgsvägen 8...\n",
      "CALCULATING FOR Frestavägen 24...\n",
      "CALCULATING FOR Turebergs Allé 19...\n",
      "CALCULATING FOR Margreteborgsvägen 23...\n",
      "CALCULATING FOR Flygarevägen 28...\n",
      "CALCULATING FOR Flygarevägen 28...\n",
      "CALCULATING FOR Turebergs allé 30 5 tr...\n",
      "CALCULATING FOR Turebergs allé 22...\n",
      "CALCULATING FOR Hovslagarevägen 19...\n",
      "CALCULATING FOR Attundagränd 5...\n",
      "CALCULATING FOR Rävgärdsvägen 17...\n",
      "CALCULATING FOR Sörmlandsvägen 8...\n",
      "CALCULATING FOR Minervavägen 28...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [28/Nov/2020 08:31:01] \"\u001b[37mGET /predict?area=sollentuna&keys=&min_year=1980&relevant_only=yes&sold_age=6m&loan_limit=3000000&dest_street=mariatorget HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    }
   ],
   "source": [
    "# 1 create the flask env\n",
    "app = Flask(__name__)\n",
    "#Swagger(app)\n",
    "\n",
    "# 2 Open the file \n",
    "pickle_in1 = open(\"scraper2.pkl\",\"rb\")\n",
    "scraper2 = pickle.load(pickle_in1)\n",
    "\n",
    "pickle_in2 = open(\"url_extractor.pkl\",\"rb\")\n",
    "url_extractor = pickle.load(pickle_in2)\n",
    "\n",
    "pickle_in3 = open(\"pct_change_metric.pkl\",\"rb\")\n",
    "pct_change_metric = pickle.load(pickle_in3)\n",
    "\n",
    "@app.route('/')\n",
    "def welcome():\n",
    "    return render_template('index.html')\n",
    "\n",
    "@app.route('/predict',methods=[\"GET\"])\n",
    "def predict():\n",
    "    \n",
    "    # Remember to add new parameters here: \n",
    "    area = request.args.get(\"area\")\n",
    "    keys = request.args.get(\"keys\")\n",
    "    min_year = request.args.get(\"min_year\")\n",
    "    current_url = request.args.get(\"current_url\")\n",
    "    relevant_only = request.args.get(\"relevant_only\")\n",
    "    sold_age = request.args.get(\"sold_age\")\n",
    "    loan_limit = request.args.get(\"loan_limit\")\n",
    "    dest_street = request.args.get(\"dest_street\") # test \n",
    "\n",
    "    current_url_new = url_extractor(area, keys, min_year )\n",
    "\n",
    "    df = scraper2(current_url = current_url_new ,relevant_only = relevant_only ,sold_age = sold_age,loan_limit = int(loan_limit), dest_street = dest_street)\n",
    "\n",
    "    \n",
    "    return render_template('view.html',tables=[df.to_html(classes ='scraper')],\n",
    "    titles = ['na', 'Results'])\n",
    "\n",
    "@app.route('/comparison',methods=[\"GET\"])\n",
    "def compare_pct():\n",
    " \n",
    "    # Remember to add new parameters here: \n",
    "     \n",
    "    area = request.args.get(\"area\")\n",
    "    num_pages = request.args.get(\"num_pages\")\n",
    "    metric = request.args.get(\"metric\")\n",
    "\n",
    "    output = pct_change_metric(area = area, num_pages = num_pages , metric = metric )\n",
    "\n",
    "    return output\n",
    "\n",
    "if __name__=='__main__':\n",
    "    app.run()\n",
    "    \n",
    "\n",
    "# if __name__=='__main__':\n",
    "#     app.run(host='0.0.0.0',port=8000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Docker\n",
    "https://www.youtube.com/watch?v=cDwsaQoP4Lk&list=PLZoTAELRMXVNKtpy0U_Mx9N26w8n0hIbs&index=6 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GitHub pull request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/Tabe/Desktop/Courses/Data-Science /Test-Projects/Python-Projects/HemnetScraper\r\n"
     ]
    }
   ],
   "source": [
    "! pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already up to date.\n",
      "[master 789afea] Last run on 2020-11-22 08:50:50.805251\n",
      " 11 files changed, 1663 insertions(+), 394 deletions(-)\n",
      " rewrite HemnetScraper/__pycache__/Scraper.cpython-37.pyc (76%)\n",
      " rename HemnetScraper/{hemnet_scraper_requirements.txt => requirements.txt} (75%)\n",
      "Enumerating objects: 26, done.\n",
      "Counting objects: 100% (26/26), done.\n",
      "Delta compression using up to 4 threads\n",
      "Compressing objects: 100% (14/14), done.\n",
      "Writing objects: 100% (15/15), 12.84 KiB | 1.28 MiB/s, done.\n",
      "Total 15 (delta 7), reused 0 (delta 0)\n",
      "remote: Resolving deltas: 100% (7/7), completed with 6 local objects.\u001b[K\n",
      "To https://github.com/tabers77/Python-Projects.git\n",
      "   b9ba165..789afea  master -> master\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "\n",
    "# 2 Pull request\n",
    "! git pull\n",
    "\n",
    "# 3\n",
    "now = datetime.datetime.now()\n",
    "commit_message = \"Last run on \" + str(now)\n",
    "! cd '/Users/Tabe/Desktop/Courses/Data-Science /Test-Projects/Python-Projects/HemnetScraper'\n",
    "! echo $commit_message > commit_message.txt\n",
    "! git add . \n",
    "! git commit -F commit_message.txt\n",
    "! git push origin master # here I choose either master or branch \n",
    "print ('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hemnet_env",
   "language": "python",
   "name": "hemnet_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
